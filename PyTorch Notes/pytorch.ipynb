{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e6ddcf",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "Source: @python-engineer PyTorch Full Course:\n",
    "`https://youtu.be/c36lUUr864M`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04baaef7",
   "metadata": {},
   "source": [
    "##### Empty tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39df0e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([-1.0538e+16,  4.5907e-41,  0.0000e+00])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 2.1019e-44],\n",
      "        [0.0000e+00, 2.1088e+03, 7.1606e-43]])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.empty(size): uninitiallized\n",
    "x = torch.empty(1) # scalar\n",
    "print(x)\n",
    "x = torch.empty(3) # vector, 1D\n",
    "print(x)\n",
    "x = torch.empty(2,3) # matrix, 2D\n",
    "print(x)\n",
    "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
    "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcc206",
   "metadata": {},
   "source": [
    "##### Random tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00bc8367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3762, 0.7166, 0.4697],\n",
      "        [0.3289, 0.7757, 0.6492],\n",
      "        [0.2014, 0.3953, 0.6824],\n",
      "        [0.1781, 0.1554, 0.9202],\n",
      "        [0.6286, 0.5183, 0.0193]])\n"
     ]
    }
   ],
   "source": [
    "# torch.rand(size): random numbers [0, 1]\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785312ed",
   "metadata": {},
   "source": [
    "##### Filling tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f8b8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.zeros(size), fill with 0\n",
    "# torch.ones(size), fill with 1\n",
    "x = torch.zeros(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ca4ca",
   "metadata": {},
   "source": [
    "##### Types and sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0c56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# check size\n",
    "print(x.size())\n",
    "\n",
    "# check data type\n",
    "print(x.dtype)\n",
    "\n",
    "# specify types, float32 default\n",
    "x = torch.zeros(5, 3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "# check type\n",
    "print(x.dtype)\n",
    "\n",
    "# construct from data\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eefb6",
   "metadata": {},
   "source": [
    "##### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d874928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2694, 0.0163, 0.7038],\n",
      "        [0.7286, 0.3055, 0.0925],\n",
      "        [0.7487, 0.4426, 0.8292],\n",
      "        [0.6845, 0.4604, 0.6008],\n",
      "        [0.3900, 0.3342, 0.6532]])\n",
      "tensor([0.2694, 0.7286, 0.7487, 0.6845, 0.3900])\n",
      "tensor([0.7286, 0.3055, 0.0925])\n",
      "tensor(0.3055)\n",
      "0.30553293228149414\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(2, 2)\n",
    "x = torch.rand(2, 2)\n",
    "\n",
    "# elementwise addition\n",
    "z = x + y\n",
    "# torch.add(x,y)\n",
    "\n",
    "# in place addition, everythin with a trailing underscore is an inplace operation\n",
    "# i.e. it will modify the variable\n",
    "# y.add_(x)\n",
    "\n",
    "# substraction\n",
    "z = x - y\n",
    "z = torch.sub(x, y)\n",
    "\n",
    "# multiplication\n",
    "z = x * y\n",
    "z = torch.mul(x,y)\n",
    "\n",
    "# division\n",
    "z = x / y\n",
    "z = torch.div(x,y)\n",
    "\n",
    "# Slicing\n",
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[:, 0]) # all rows, column 0\n",
    "print(x[1, :]) # row 1, all columns\n",
    "print(x[1,1]) # element at 1, 1\n",
    "\n",
    "# Get the actual value if only 1 element in your tensor\n",
    "print(x[1,1].item())\n",
    "\n",
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "# if -1 it pytorch will automatically determine the necessary size\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6cb09",
   "metadata": {},
   "source": [
    "##### Interacting with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "# torch to numpy with .numpy()\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))\n",
    "\n",
    "# Careful: If the Tensor is on the CPU (not the GPU),\n",
    "# both objects will share the same memory location, so changing one\n",
    "# will also change the other\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# numpy to torch with .from_numpy(x)\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e705ee6",
   "metadata": {},
   "source": [
    "##### Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default all tensors are created on the CPU,\n",
    "# but you can also move them to the GPU (only if it's available )\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
    "    # move to CPU again\n",
    "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
    "    # z = z.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddd07b",
   "metadata": {},
   "source": [
    "##### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daed68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad argument\n",
    "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
    "# later in your optimization steps\n",
    "# i.e. this is a variable in your model that you want to optimize\n",
    "x = torch.tensor([5.5, 3], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374a2939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2682, 0.8377, 0.0495], requires_grad=True)\n",
      "tensor([2.2682, 2.8377, 2.0495], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000001FF33D61460>\n",
      "tensor([15.4345, 24.1571, 12.6019], grad_fn=<MulBackward0>)\n",
      "tensor(17.3978, grad_fn=<MeanBackward0>)\n",
      "tensor([4.5364, 5.6753, 4.0991])\n"
     ]
    }
   ],
   "source": [
    "# The autograd package provides automatic differentiation \n",
    "# for all operations on Tensors\n",
    "\n",
    "# requires_grad = True -> tracks all operations on the tensor. \n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x + 2\n",
    "\n",
    "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
    "# grad_fn: references a Function that has created the Tensor\n",
    "print(x) # created by the user -> grad_fn is None\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "\n",
    "# Do more operations on y\n",
    "z = y * y * 3\n",
    "print(z)\n",
    "z = z.mean()\n",
    "print(z)\n",
    "\n",
    "# Let's compute the gradients with backpropagation\n",
    "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
    "# The gradient for this tensor will be accumulated into .grad attribute.\n",
    "# It is the partial derivate of the function w.r.t. the tensor\n",
    "\n",
    "z.backward()\n",
    "print(x.grad) # dz/dx\n",
    "\n",
    "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
    "# It computes partial derivates while applying the chain rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8775f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 871.9336, -142.0997, 4293.4995], grad_fn=<MulBackward0>)\n",
      "torch.Size([3])\n",
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
     ]
    }
   ],
   "source": [
    "# Model with non-scalar output:\n",
    "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward() \n",
    "# specify a gradient argument that is a tensor of matching shape.\n",
    "# needed for vector-Jacobian product\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "for _ in range(10):\n",
    "    y = y * 2\n",
    "\n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop a tensor from tracking history:\n",
    "# For example during our training loop when we want to update our weights\n",
    "# then this update operation should not be part of the gradient computation\n",
    "# - x.requires_grad_(False)\n",
    "# - x.detach()\n",
    "# - wrap in 'with torch.no_grad():'\n",
    "\n",
    "# .requires_grad_(...) changes an existing flag in-place.\n",
    "a = torch.randn(2, 2)\n",
    "print(a.requires_grad)\n",
    "b = ((a * 3) / (a - 1))\n",
    "print(b.grad_fn)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)\n",
    "\n",
    "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "b = a.detach()\n",
    "print(b.requires_grad)\n",
    "\n",
    "# wrap in 'with torch.no_grad():'\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
    "# !!! We need to be careful during optimization !!!\n",
    "# Use .zero_() to empty the gradients before a new optimization step!\n",
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    # just a dummy example\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n",
    "\n",
    "    # optimize model, i.e. adjust weights...\n",
    "    with torch.no_grad():\n",
    "        weights -= 0.1 * weights.grad\n",
    "\n",
    "    # this is important! It affects the final weights & output\n",
    "    weights.grad.zero_()\n",
    "\n",
    "print(weights)\n",
    "print(model_output)\n",
    "\n",
    "# Optimizer has zero_grad() method\n",
    "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
    "# During training:\n",
    "# optimizer.step()\n",
    "# optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15e8db",
   "metadata": {},
   "source": [
    "##### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f88db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "# This is the parameter we want to optimize -> requires_grad=True\n",
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass to compute loss\n",
    "y_predicted = w * x\n",
    "loss = (y_predicted - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass to compute gradient dLoss/dw\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "# update weights\n",
    "# next forward and backward pass...\n",
    "\n",
    "# continue optimizing:\n",
    "# update weights, this operation should not be part of the computational graph\n",
    "with torch.no_grad():\n",
    "    w -= 0.01 * w.grad\n",
    "# don't forget to zero the gradients\n",
    "w.grad.zero_()\n",
    "\n",
    "# next forward and backward pass..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3593a",
   "metadata": {},
   "source": [
    "#### Learning example with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d05da09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "epoch 1: w = 3.000, loss = 187.50000000\n",
      "epoch 3: w = 4.680, loss = 4.80000210\n",
      "epoch 5: w = 4.949, loss = 0.12288050\n",
      "epoch 7: w = 4.992, loss = 0.00314578\n",
      "epoch 9: w = 4.999, loss = 0.00008053\n",
      "epoch 11: w = 5.000, loss = 0.00000206\n",
      "epoch 13: w = 5.000, loss = 0.00000005\n",
      "epoch 15: w = 5.000, loss = 0.00000000\n",
      "epoch 17: w = 5.000, loss = 0.00000000\n",
      "epoch 19: w = 5.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 25.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Compute every step manually\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y = np.array([5, 10, 15, 20], dtype=np.float32)\n",
    "\n",
    "w = 0.0\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# J = MSE = 1/N * (w*x - y)**2\n",
    "# dJ/dw = 1/N * 2x(w*x - y)\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred - y).mean()\n",
    "\n",
    "# np.dot([1D], [1D]) --> scalar product (inner product)\n",
    "# Instead of substracting dw in each iteration of the current epoch \n",
    "# We have sum of dw in this inner product\n",
    "# So we can simply substract it from the w in the end of epoch iteration\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "    \n",
    "    # calculate gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "    # print(f'dw = {dw}')\n",
    "\n",
    "    # update weights\n",
    "    w -= learning_rate * dw\n",
    "    # We have sum of dw1, dw2... dw4 in dw \n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "     \n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e891714",
   "metadata": {},
   "source": [
    "#### Learning example with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3036d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Here we replace the manually computed gradient with autograd\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# model output\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    #w.data = w.data - learning_rate * w.grad\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "    \n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb053b",
   "metadata": {},
   "source": [
    "##### Using Torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78656de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Design model (input, output, forward pass with different layers)\n",
    "# 2) Construct loss and optimizer\n",
    "# 3) Training loop\n",
    "#       - Forward = compute prediction and loss\n",
    "#       - Backward = compute gradients\n",
    "#       - Update weights\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "\n",
    "# 0) Training samples, watch the shape!\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)  # 4x1 matrix\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape  # n_samples = 4, n_features = 1\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "\n",
    "# we can call this model with samples X\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# Example shows how to realize your own linear regression\n",
    "# Example works the same way as nn.Linear does \n",
    "'''\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        # define diferent layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.lin(x)\n",
    "model = LinearRegression(input_size, output_size)\n",
    "'''\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        [w, b] = model.parameters() # unpack parameters\n",
    "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf364f9",
   "metadata": {},
   "source": [
    "#### Linear approximation with PyTorch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b180a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) Prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
    "\n",
    "# cast to float Tensor\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) Model\n",
    "# Linear model f = wx + b\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# 3) Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "# Plot\n",
    "predicted = model(X).detach().numpy()\n",
    "\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1604ee",
   "metadata": {},
   "source": [
    "#### Logistic Regression (sigmoid as output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8c8f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.5755\n",
      "epoch: 20, loss = 0.4749\n",
      "epoch: 30, loss = 0.4109\n",
      "epoch: 40, loss = 0.3665\n",
      "epoch: 50, loss = 0.3338\n",
      "epoch: 60, loss = 0.3085\n",
      "epoch: 70, loss = 0.2882\n",
      "epoch: 80, loss = 0.2714\n",
      "epoch: 90, loss = 0.2573\n",
      "epoch: 100, loss = 0.2451\n",
      "accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) Prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "# Recommended while dealing with logistic regression\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "# 1) Model\n",
    "# Linear model f = wx + b , sigmoid at the end\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "# model parameters: w1x1 + w2x2 + ... + w30x30 + b\n",
    "# model.parameters() --> w: torch.tensor (1, 30), b: torch.tensor (1)\n",
    "model = Model(n_features)\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# returns loss percentage!\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f1dca",
   "metadata": {},
   "source": [
    "#### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da75656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n",
      "tensor([[1.2080e+01, 1.8300e+00, 2.3200e+00, 1.8500e+01, 8.1000e+01, 1.6000e+00,\n",
      "         1.5000e+00, 5.2000e-01, 1.6400e+00, 2.4000e+00, 1.0800e+00, 2.2700e+00,\n",
      "         4.8000e+02],\n",
      "        [1.2930e+01, 2.8100e+00, 2.7000e+00, 2.1000e+01, 9.6000e+01, 1.5400e+00,\n",
      "         5.0000e-01, 5.3000e-01, 7.5000e-01, 4.6000e+00, 7.7000e-01, 2.3100e+00,\n",
      "         6.0000e+02],\n",
      "        [1.3080e+01, 3.9000e+00, 2.3600e+00, 2.1500e+01, 1.1300e+02, 1.4100e+00,\n",
      "         1.3900e+00, 3.4000e-01, 1.1400e+00, 9.4000e+00, 5.7000e-01, 1.3300e+00,\n",
      "         5.5000e+02],\n",
      "        [1.2210e+01, 1.1900e+00, 1.7500e+00, 1.6800e+01, 1.5100e+02, 1.8500e+00,\n",
      "         1.2800e+00, 1.4000e-01, 2.5000e+00, 2.8500e+00, 1.2800e+00, 3.0700e+00,\n",
      "         7.1800e+02]]) tensor([[2.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "178 45\n",
      "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
      "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# gradient computation etc. not efficient for whole data set\n",
    "# -> divide dataset into small batches\n",
    "\n",
    "'''\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over all batches\n",
    "    for i in range(total_batches):\n",
    "        batch_x, batch_y = ...\n",
    "'''\n",
    "\n",
    "# epoch = one forward and backward pass of ALL training samples\n",
    "# batch_size = number of training samples used in one forward/backward pass\n",
    "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
    "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
    "\n",
    "# --> DataLoader can do the batch computation for us\n",
    "\n",
    "# Implement a custom Dataset:\n",
    "# inherit Dataset\n",
    "# implement __init__ , __getitem__ , and __len__\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('../ML/LogicsticRegression/batches/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# create dataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)\n",
    "\n",
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading with multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "# convert to an iterator and look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "\n",
    "# Dummy Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
    "\n",
    "# some famous datasets are available in torchvision.datasets\n",
    "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
    "\n",
    "# train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "#                                            train=True, \n",
    "#                                            transform=torchvision.transforms.ToTensor(),  \n",
    "#                                            download=True)\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, \n",
    "#                                            batch_size=3, \n",
    "#                                            shuffle=True)\n",
    "\n",
    "# look at one random sample\n",
    "# dataiter = iter(train_loader)\n",
    "# data = dataiter.next()\n",
    "# inputs, targets = data\n",
    "# print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cac8bc",
   "metadata": {},
   "source": [
    "#### torchvision.transforms for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466e3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Transform\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n",
      "\n",
      "With Tensor Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n",
      "\n",
      "With Tensor and Multiplication Transform\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
      "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
      "        4.2600e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
    "during creation of the DataSet\n",
    "complete list of built-in transforms: \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "On Images\n",
    "---------\n",
    "CenterCrop, Grayscale, Pad, RandomAffine\n",
    "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
    "Resize, Scale\n",
    "On Tensors\n",
    "----------\n",
    "LinearTransformation, Normalize, RandomErasing\n",
    "Conversion\n",
    "----------\n",
    "ToPILImage: from tensor or ndrarray\n",
    "ToTensor : from numpy.ndarray or PILImage\n",
    "Generic\n",
    "-------\n",
    "Use Lambda \n",
    "Custom\n",
    "------\n",
    "Write own class\n",
    "Compose multiple Transforms\n",
    "---------------------------\n",
    "composed = transforms.Compose([Rescale(256),\n",
    "                               RandomCrop(224)])\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('/home/srg/Documents/libs/PyTorch/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # note that we do not convert to tensor here\n",
    "        self.x_data = xy[:, 1:]\n",
    "        self.y_data = xy[:, [0]]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        # Returns transformed sample\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "# Custom Transforms\n",
    "# implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "class MulTransform:\n",
    "    # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "\n",
    "print('Without Transform')\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)\n",
    "\n",
    "print('\\nWith Tensor and Multiplication Transform')\n",
    "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset = WineDataset(transform=composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(type(features), type(labels))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2406e1",
   "metadata": {},
   "source": [
    "#### Softmax and Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6fb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "#        -> 2.0              -> 0.65  \n",
    "# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n",
    "#        -> 0.1              -> 0.1                   \n",
    "#\n",
    "#     scores(logits)      probabilities\n",
    "#                           sum = 1.0\n",
    "#\n",
    "\n",
    "# Softmax applies the exponential function to each element, and normalizes\n",
    "# by dividing by the sum of all these exponentials\n",
    "# -> squashes the output to be between 0 and 1 = probability\n",
    "# sum of all probabilities is 1\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "outputs = softmax(x)\n",
    "print('softmax numpy:', outputs)\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
    "print('softmax torch:', outputs)\n",
    "\n",
    "# Cross entropy\n",
    "# Cross-entropy loss, or log loss, measures the performance of a classification model \n",
    "# whose output is a probability value between 0 and 1. \n",
    "# -> loss increases as the predicted probability diverges from the actual label\n",
    "def cross_entropy(actual, predicted):\n",
    "    EPS = 1e-15\n",
    "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "# y must be one hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "Y = np.array([1, 0, 0])\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f'Loss1 numpy: {l1:.4f}')\n",
    "print(f'Loss2 numpy: {l2:.4f}')\n",
    "\n",
    "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
    "# nn.LogSoftmax + nn.NLLLoss\n",
    "# NLLLoss = negative log likelihood loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "# loss(input, target)\n",
    "\n",
    "# target is of size nSamples = 1\n",
    "# each element has class label: 0, 1, or 2\n",
    "# Y (=target) contains class labels, not one-hot\n",
    "Y = torch.tensor([0])\n",
    "\n",
    "# input is of size nSamples x nClasses = 1 x 3\n",
    "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
    "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
    "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
    "\n",
    "# allows batch loss for multiple samples\n",
    "\n",
    "# target is of size nBatch = 3\n",
    "# each element has class label: 0, 1, or 2\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9], # predict class 2\n",
    "    [1.2, 0.1, 0.3], # predict class 0\n",
    "    [0.3, 2.2, 0.2]]) # predict class 1\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
    "\n",
    "# Binary classification\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # sigmoid at the end\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()  # (applies Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce70b28",
   "metadata": {},
   "source": [
    "#### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f5ecc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = w*x + b\n",
    "# output = activation_function(output)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6870a347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
      "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n"
     ]
    }
   ],
   "source": [
    "# softmax\n",
    "output = torch.softmax(x, dim=0)\n",
    "print(output)\n",
    "sm = nn.Softmax(dim=0)\n",
    "output = sm(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a90865f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
      "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sigmoid \n",
    "output = torch.sigmoid(x)\n",
    "print(output)\n",
    "s = nn.Sigmoid()\n",
    "output = s(x)\n",
    "print(output)\n",
    "\n",
    "# plot\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,100)\n",
    "fig = plt.figure()\n",
    "plt.plot(y,sigmoid(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-2, -1, 0, 1, 2])\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dafa381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
      "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tanh\n",
    "output = torch.tanh(x)\n",
    "print(output)\n",
    "t = nn.Tanh()\n",
    "output = t(x)\n",
    "print(output)\n",
    "\n",
    "# plot \n",
    "tanh = lambda x: 2*sigmoid(2*x)-1\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,100)\n",
    "plt.plot(y,tanh(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('TanH Function')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.ylim(-4, 4)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e75abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# relu\n",
    "output = torch.relu(x)\n",
    "print(output)\n",
    "relu = nn.ReLU()\n",
    "output = relu(x)\n",
    "print(output)\n",
    "\n",
    "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
    "#torch.relu on the other side is just the functional API call to the relu function,\n",
    "#so that you can add it e.g. in your forward method yourself.\n",
    "\n",
    "# plot\n",
    "relu = lambda x: np.where(x>=0, x, 0)\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,1000)\n",
    "plt.plot(y,relu(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('ReLU')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.ylim(-4, 4)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "994736a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
      "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# leaky relu\n",
    "output = F.leaky_relu(x)\n",
    "print(output)\n",
    "lrelu = nn.LeakyReLU()\n",
    "output = lrelu(x)\n",
    "print(output)\n",
    "\n",
    "# plot\n",
    "leakyrelu = lambda x: np.where(x>=0, x, 0.1*x)\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,1000)\n",
    "plt.plot(y,leakyrelu(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('Leaky ReLU')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.ylim(-4, 4)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ce19f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Binary Step\n",
    "bstep = lambda x: np.where(x>=0, 1, 0)\n",
    "x=np.linspace(-10,10,10)\n",
    "y=np.linspace(-10,10,1000)\n",
    "plt.plot(y,bstep(y),'b', label='linspace(-10,10,100)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.title('Step Function')\n",
    "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "plt.yticks([-2, -1, 0, 1, 2])\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(-4, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c96159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1 (create nn modules)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# option 2 (use activation functions directly in forward pass)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf598ade",
   "metadata": {},
   "source": [
    "#### Feed Forward Net Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4132ff99",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4195/1920235865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     download_and_extract_archive(\n\u001b[0m\u001b[1;32m    177\u001b[0m                         \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# device configuration \n",
    "# we use Cuda on GPU if possible \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# hyper parameters \n",
    "\n",
    "input_size = 784 # images are 28x28\n",
    "hidden_size = 100 # can be different \n",
    "num_classes = 10 # 10 different digits are available \n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# check random sample \n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, label = examples.next()\n",
    "\n",
    "# print(samples.shape, label.shape)\n",
    "\n",
    "# Show some pictures \n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "# Neural Network \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out) # We don't apply softmax() here because we will use Cross Entropy below \n",
    "        return out\n",
    "\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# loss & optimizer \n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # applying softmax()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# training loop \n",
    "\n",
    "total_samples = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        # (100, 1, 28, 28) --> (100, 784)\n",
    "        images = images.reshape(-1, 28 * 28)\n",
    "\n",
    "        # moving to GPU if possible \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # info \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs} | Step {i+1}/{total_samples} | Loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# testing \n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0 \n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # value, index\n",
    "        _, predictions = torch.max(outputs, 1) # 1 = along rows\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "        n_samples += labels.shape[0]\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy = {acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08235b06",
   "metadata": {},
   "source": [
    "#### Convolutional networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c627dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Normalize:\n",
    "\n",
    "# torchvision.transforms.Normalize(mean, std, inplace=False)\n",
    "# Normalize a tensor image with mean and standard deviation.\n",
    "# This transform does not support PIL Image. Given mean: (mean[1],...,mean[n])\n",
    "# and std: (std[1],..,std[n]) for n channels, this transform will normalize each\n",
    "# channel of the input torch.*Tensor i.e.,\n",
    "# output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    # conv --> relu --> pool --> conv --> relu --> pool --> linear --> relu --> linear --> relu --> linear\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "                                              # No softmax() as it's already applied in CrossEntropyLoss\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63575431",
   "metadata": {},
   "source": [
    "#### Transfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8882ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n",
    "\n",
    "\n",
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "#### Finetuning the convnet ####\n",
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# Learning rate scheduling should be applied after optimizer’s update\n",
    "# e.g., you should write your code this way:\n",
    "# for epoch in range(100):\n",
    "#     train(...)\n",
    "#     validate(...)\n",
    "#     scheduler.step()\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
    "\n",
    "\n",
    "#### ConvNet as fixed feature extractor ####\n",
    "# Here, we need to freeze all the network except the final layer.\n",
    "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f3656",
   "metadata": {},
   "source": [
    "#### Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a0eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "''' 3 DIFFERENT METHODS TO REMEMBER:\n",
    " - torch.save(arg, PATH) # can be model, tensor, or dictionary\n",
    " - torch.load(PATH)\n",
    " - torch.load_state_dict(arg)\n",
    "'''\n",
    "\n",
    "''' 2 DIFFERENT WAYS OF SAVING\n",
    "# 1) lazy way: save whole model\n",
    "torch.save(model, PATH)\n",
    "# model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "# 2) recommended way: save only the state_dict\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# model must be created again with parameters\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "'''\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "# train your model...\n",
    "\n",
    "####################save all ######################################\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "# save and load entire model\n",
    "\n",
    "FILE = \"model.pth\"\n",
    "torch.save(model, FILE)\n",
    "\n",
    "loaded_model = torch.load(FILE)\n",
    "loaded_model.eval()\n",
    "\n",
    "for param in loaded_model.parameters():\n",
    "    print(param)\n",
    "\n",
    "\n",
    "############save only state dict #########################\n",
    "\n",
    "# save only state dict\n",
    "FILE = \"model.pth\"\n",
    "torch.save(model.state_dict(), FILE)\n",
    "\n",
    "print(model.state_dict())\n",
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
    "loaded_model.eval()\n",
    "\n",
    "print(loaded_model.state_dict())\n",
    "\n",
    "\n",
    "###########load checkpoint#####################\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "checkpoint = {\n",
    "\"epoch\": 90,\n",
    "\"model_state\": model.state_dict(),\n",
    "\"optim_state\": optimizer.state_dict()\n",
    "}\n",
    "print(optimizer.state_dict())\n",
    "FILE = \"checkpoint.pth\"\n",
    "torch.save(checkpoint, FILE)\n",
    "\n",
    "model = Model(n_input_features=6)\n",
    "optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
    "\n",
    "checkpoint = torch.load(FILE)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "epoch = checkpoint['epoch']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "# model.train()\n",
    "\n",
    "print(optimizer.state_dict())\n",
    "\n",
    "# Remember that you must call model.eval() to set dropout and batch normalization layers \n",
    "# to evaluation mode before running inference. Failing to do this will yield \n",
    "# inconsistent inference results. If you wish to resuming training, \n",
    "# call model.train() to ensure these layers are in training mode.\n",
    "\n",
    "\"\"\" SAVING ON GPU/CPU \n",
    "# 1) Save on GPU, Load on CPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "device = torch.device('cpu')\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "# 2) Save on GPU, Load on GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "# Note: Be sure to use the .to(torch.device('cuda')) function \n",
    "# on all model inputs, too!\n",
    "# 3) Save on CPU, Load on GPU\n",
    "torch.save(model.state_dict(), PATH)\n",
    "device = torch.device(\"cuda\")\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
    "model.to(device)\n",
    "# This loads the model to a given GPU device. \n",
    "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
